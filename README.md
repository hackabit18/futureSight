# futureSight
- An Efficient way to guide the user through the enviornment to the desired object to be accessed. 
- Designing a band(**BLINK band**) which has CPU and a motor control unit which uses a 2 stage **Deep Learning** Mechanism.
- This Guides the user Giving **Haptic Feedback** from Vibration motors efficiently and intractively through the use of **Google Assistant** for voice INPUT and OUTPUT.
- Our BLINK band solves the problem of Difficulty for blind people in accessing NearBy and Day-to-Day Objects 
- This Eliminates the dependency of Blind People on other people in their daily life.
- **Components** Used : Raspi 3b , Andruino mega2560 , Pycam 2 , microphone-speaker , vibration motors
- **Tools/Frameworks** Used: Tensorflow(GPU) , Google Assistant SDK ,  nanpy.
